{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Домашнее задание\n",
        "1. Возьмите готовую модель из https://huggingface.co/models для классификации сентимента текста.\n",
        "2. Сделайте предсказания на всем df_val. Посчитайте метрику качества.\n",
        "3. Дообучите эту модель на df_train. Посчитайте метрику качества на df_val.\n",
        "\n",
        "Данные на google drive: https://drive.google.com/file/d/1Mev_EEput0LlBj8MDHIJkBtahlJ6J901"
      ],
      "metadata": {
        "id": "Q6we4EuXqHWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подключение библиотек**"
      ],
      "metadata": {
        "id": "B-SQ7cp-qZDD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qWNYpQPprzK",
        "outputId": "01a0abac-8657-4700-ee44-3332c21c4486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tyv9rosqsSE",
        "outputId": "20d44b82-552a-4036-dc4e-3cba0c34da36"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.9/dist-packages (0.11.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.10.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchmetrics import F1Score"
      ],
      "metadata": {
        "id": "J4Z6EyIjqxXL"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wcH8e9udq3_L",
        "outputId": "5693344d-2eef-4a1a-825f-04dd6e6f00a7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlxD4JqotOHD",
        "outputId": "fb7ff316-9441-4fea-bf0b-f01bcbdf1b81"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/data/train.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/data/val.csv\")\n",
        "\n",
        "df_train.shape, df_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9Wossrjq7qq",
        "outputId": "51a7233d-771d-4519-acf3-f10001cecb4f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((181467, 3), (22683, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KGy23VZMtgvL",
        "outputId": "42510a0c-1bf8-453e-d17a-55eca1f07c94"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                               text  class\n",
              "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
              "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
              "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
              "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
              "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6bb750e-c4a8-4e86-a71e-916b49f3ef4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6bb750e-c4a8-4e86-a71e-916b49f3ef4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6bb750e-c4a8-4e86-a71e-916b49f3ef4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6bb750e-c4a8-4e86-a71e-916b49f3ef4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('cointegrated/rubert-tiny-toxicity')\n",
        "model = BertForSequenceClassification.from_pretrained('cointegrated/rubert-tiny-toxicity')"
      ],
      "metadata": {
        "id": "dFhfdezDtnTK"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка работы модели\n",
        "sentiment = pipeline(\"text-classification\", model='cointegrated/rubert-tiny-toxicity')\n",
        "sentiment(\"Хорошая погода\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxH-J_nOts5c",
        "outputId": "fa71988e-625f-4e8a-888b-2385d3a81b92"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'non-toxic', 'score': 0.9994722008705139}]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Проверка работы токенайзера\n",
        "\n",
        "example_text = 'Пример текста для токенизации'\n",
        "bert_input = tokenizer(example_text, padding='max_length', max_length=15, \n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "print(bert_input['input_ids'])\n",
        "print(bert_input['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc5AzCwztwbz",
        "outputId": "ff119f85-a8eb-46d8-c7f8-919337d8e985"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    2,  3086, 10885, 22723,   871, 24302,  3464, 10880,     3,     0,\n",
            "             0,     0,     0,     0,     0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка параметров модели\n",
        "print(model)\n",
        "print(\"Parameters full train:\", sum([param.nelement() for param in model.parameters()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVLCYME0t0l8",
        "outputId": "d4c5f407-dcf9-4266-efa2-fe908771a8ff"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(29564, 312, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 312)\n",
            "      (token_type_embeddings): Embedding(2, 312)\n",
            "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-2): 3 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
            "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
            "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=312, out_features=5, bias=True)\n",
            ")\n",
            "Parameters full train: 11785733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подготовка данных**"
      ],
      "metadata": {
        "id": "Uj9XhYuVt330"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 20\n",
        "print(df_train.iloc[idx]['text'])\n",
        "print('label is', df_train.iloc[idx]['class'])\n",
        "sentiment(df_train.iloc[idx]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZLbwnQ6t5Ck",
        "outputId": "8ba5b8b9-c2df-4500-d5a2-89b7b4084e47"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Австрия ждеееет! Последние формальности уладили) Буду сегодня паковать чемодан!))\n",
            "label is 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'non-toxic', 'score': 0.9992603659629822}]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['text'] = df_train['text'].apply(lambda x: x.lower())\n",
        "df_val['text'] = df_val['text'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "4EWEFA97t9cD"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O1EceVjt_0j",
        "outputId": "967ac7cc-94a7-492f-d667-41c3d7d90d64"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.Dataset"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TwitterDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, txts, labels):\n",
        "        self._labels = labels\n",
        "        \n",
        "        self.tokenizer = BertTokenizer.from_pretrained('cointegrated/rubert-tiny-toxicity')\n",
        "        self._txts = [self.tokenizer(text, padding='max_length', max_length=10,\n",
        "                                     truncation=True, return_tensors=\"pt\")\n",
        "                      for text in txts]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self._txts)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self._txts[index], self._labels[index]"
      ],
      "metadata": {
        "id": "IUKTmn56uDgb"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataLoader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZipEkynRuEmz",
        "outputId": "6214e083-0098-499d-ff30-d0c69c6123cf"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df_train['class']\n",
        "y_val = df_val['class']\n",
        "\n",
        "train_dataset = TwitterDataset(df_train['text'], y_train)\n",
        "valid_dataset = TwitterDataset(df_val['text'], y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "valid_loader = DataLoader(valid_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=False,\n",
        "                          num_workers=0)"
      ],
      "metadata": {
        "id": "cH5KbF9puI9y"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for txt, lbl in train_loader:\n",
        "    print(txt.keys())\n",
        "    print(txt['input_ids'].shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv1xFBG9umaV",
        "outputId": "6d9ef370-bf7b-4002-945c-dfd89c7c11d1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "torch.Size([128, 1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Построение и обучение нейронной сети**"
      ],
      "metadata": {
        "id": "4k7RhpT5upOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.pretrained_model = BertForSequenceClassification.from_pretrained('cointegrated/rubert-tiny-toxicity')\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        pooled_output = self.pretrained_model(input_ids=x, attention_mask=mask,return_dict=False)[0]\n",
        "        final = self.sigm(pooled_output)\n",
        "        return final"
      ],
      "metadata": {
        "id": "Zl7Sg8SzuqSr"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertClassifier().to(device)"
      ],
      "metadata": {
        "id": "SOtbPvplutLc"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.pretrained_model.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTmzjHBIutG7",
        "outputId": "9cc77e27-21f1-48b5-b156-afd8f8701b50"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=312, out_features=5, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.pretrained_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "TH_EzBoJu210"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f1 = F1Score().to(device)\n",
        "valid_f1 = F1Score().to(device)\n",
        "\n",
        "for epoch_num in range(10):\n",
        "    total_acc_train = 0\n",
        "    total_loss_train = 0\n",
        "\n",
        "    model.train()\n",
        "    for train_input, train_label in tqdm(train_loader):\n",
        "        mask = train_input['attention_mask'].to(device)\n",
        "        input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "        train_label = train_label.to(device)\n",
        "        \n",
        "        output = model(input_id, mask)\n",
        "\n",
        "        batch_loss = criterion(output, train_label)\n",
        "        total_loss_train += batch_loss.item()\n",
        "\n",
        "        train_f1(output, train_label)\n",
        "\n",
        "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "        total_acc_train += acc\n",
        "\n",
        "        model.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "            \n",
        "    model.eval()\n",
        "    total_loss_val, total_acc_val = 0.0, 0.0\n",
        "    for val_input, val_label in valid_loader:\n",
        "        val_label = val_label.to(device)\n",
        "        mask = val_input['attention_mask'].to(device)\n",
        "        input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "        output = model(input_id, mask)\n",
        "\n",
        "        batch_loss = criterion(output, val_label)\n",
        "        total_loss_val += batch_loss.item()\n",
        "                    \n",
        "        acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "        total_acc_val += acc\n",
        "\n",
        "        valid_f1(output, val_label)\n",
        "\n",
        "      \n",
        "    print(\n",
        "        f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_dataset): .3f} \\\n",
        "        | Train Accuracy: {total_acc_train / len(train_dataset): .3f} \\\n",
        "        | Train f1: {train_f1.compute().item(): .3f} \\\n",
        "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
        "        | Val Accuracy: {total_acc_val / len(valid_dataset): .3f} \\\n",
        "        | Val f1: {valid_f1.compute().item(): .3f}')\n",
        "    \n",
        "    train_f1.reset()\n",
        "    valid_f1.reset()"
      ],
      "metadata": {
        "id": "x5jGDO-xu6b7"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "100%|██████████| 1418/1418 [00:29<00:00, 48.42it/s]\n",
        "Epochs: 1 | Train Loss:  0.009         | Train Accuracy:  0.494         | Train f1:  0.494         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n",
        "\n",
        "100%|██████████| 1418/1418 [00:26<00:00, 54.38it/s]\n",
        "Epochs: 2 | Train Loss:  0.009         | Train Accuracy:  0.494         | Train f1:  0.494         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n",
        "\n",
        "100%|██████████| 1418/1418 [00:25<00:00, 54.80it/s]\n",
        "Epochs: 3 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n",
        "\n",
        "100%|██████████| 1418/1418 [00:25<00:00, 54.77it/s]\n",
        "Epochs: 4 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n",
        "\n",
        "100%|██████████| 1418/1418 [00:26<00:00, 54.33it/s]\n",
        "Epochs: 5 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n",
        "\n",
        "100%|██████████| 1418/1418 [00:25<00:00, 54.64it/s]\n",
        "Epochs: 6 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n",
        "\n",
        "100%|██████████| 1418/1418 [00:26<00:00, 53.09it/s]\n",
        "Epochs: 7 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n",
        "\n",
        "100%|██████████| 1418/1418 [00:25<00:00, 54.62it/s]\n",
        "Epochs: 8 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n",
        "\n",
        "100%|██████████| 1418/1418 [00:25<00:00, 54.66it/s]\n",
        "Epochs: 9 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495\n",
        "\n",
        "100%|██████████| 1418/1418 [00:25<00:00, 54.84it/s]\n",
        "Epochs: 10 | Train Loss:  0.009         | Train Accuracy:  0.493         | Train f1:  0.493         | Val Loss:  0.009         | Val Accuracy:  0.495         | Val f1:  0.495"
      ],
      "metadata": {
        "id": "15hczLrxz5n2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SldRL717z7Ws"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}